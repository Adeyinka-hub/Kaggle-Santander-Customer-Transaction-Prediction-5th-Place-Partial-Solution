{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sys import getsizeof\\ntmp = np.ones((400000, 6000), dtype=np.float32)\\ngetsizeof(tmp)//1024//1024\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing\n",
    "'''\n",
    "from sys import getsizeof\n",
    "tmp = np.ones((400000, 6000), dtype=np.float32)\n",
    "getsizeof(tmp)//1024//1024\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('data/train_original.pkl')\n",
    "test = pd.read_pickle('data/test_original.pkl')\n",
    "special_cols = [col for col in train.columns if train[col].dtype != np.float64]\n",
    "feature_cols = [col for col in train.columns if col not in special_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8_9255',\n",
       " '_6_7863',\n",
       " '11_9081',\n",
       " '5_093',\n",
       " '11_4607',\n",
       " '_9_2834',\n",
       " '5_1187',\n",
       " '18_6266',\n",
       " '_4_92',\n",
       " '5_747000000000001',\n",
       " '2_9252',\n",
       " '3_1821',\n",
       " '14_0137',\n",
       " '0_5745',\n",
       " '8_7989',\n",
       " '14_5691',\n",
       " '5_7487',\n",
       " '_7_2393',\n",
       " '4_284',\n",
       " '30_7133',\n",
       " '10_535',\n",
       " '16_2191',\n",
       " '2_5791',\n",
       " '2_4716',\n",
       " '14_3831',\n",
       " '13_4325',\n",
       " '_5_1488',\n",
       " '_0_4073',\n",
       " '4_9306',\n",
       " '5_9965',\n",
       " '_0_3085',\n",
       " '12_9041',\n",
       " '_3_8766',\n",
       " '16_8911',\n",
       " '11_192',\n",
       " '10_5785',\n",
       " '0_6764',\n",
       " '7_8871',\n",
       " '4_6667',\n",
       " '3_8743',\n",
       " '_5_2387',\n",
       " '7_3746',\n",
       " '11_5767',\n",
       " '12_0446',\n",
       " '11_6418',\n",
       " '_7_017',\n",
       " '5_9226',\n",
       " '_14_2136',\n",
       " '16_0283',\n",
       " '5_3253',\n",
       " '12_9194',\n",
       " '29_046',\n",
       " '_0_6940000000000001',\n",
       " '5_1736',\n",
       " '_0_7474',\n",
       " '14_8322',\n",
       " '11_2668',\n",
       " '5_3822',\n",
       " '2_0183',\n",
       " '10_1166',\n",
       " '16_1828',\n",
       " '4_959',\n",
       " '2_0771',\n",
       " '_0_2154',\n",
       " '8_6748',\n",
       " '9_5319',\n",
       " '5_8056',\n",
       " '22_4321',\n",
       " '5_0109',\n",
       " '_4_7010000000000005',\n",
       " '21_6374',\n",
       " '0_5663',\n",
       " '5_1999',\n",
       " '8_86',\n",
       " '43_1127',\n",
       " '18_3816',\n",
       " '_2_344',\n",
       " '23_4104',\n",
       " '6_5199',\n",
       " '12_1983',\n",
       " '13_6468',\n",
       " '13_8372',\n",
       " '1_3675',\n",
       " '2_9423',\n",
       " '_4_5213',\n",
       " '21_4669',\n",
       " '9_3225',\n",
       " '16_4597',\n",
       " '7_9984',\n",
       " '_1_7069',\n",
       " '_21_4494',\n",
       " '6_7806',\n",
       " '11_0924',\n",
       " '9_9913',\n",
       " '14_8421',\n",
       " '0_1812',\n",
       " '8_9642',\n",
       " '16_2572',\n",
       " '2_1743',\n",
       " '_3_4132',\n",
       " '9_4763',\n",
       " '13_3102',\n",
       " '26_5376',\n",
       " '1_4403',\n",
       " '14_71',\n",
       " '6_0454',\n",
       " '9_5426',\n",
       " '17_1554',\n",
       " '14_1104',\n",
       " '24_3627',\n",
       " '2_0323',\n",
       " '6_7602',\n",
       " '3_9141',\n",
       " '_0_4851',\n",
       " '2_524',\n",
       " '1_5093',\n",
       " '2_5516',\n",
       " '15_5752',\n",
       " '_13_4221',\n",
       " '7_2739',\n",
       " '16_0094',\n",
       " '9_7268',\n",
       " '0_8897',\n",
       " '0_7754',\n",
       " '4_2218',\n",
       " '12_0039',\n",
       " '13_8571',\n",
       " '_0_7338',\n",
       " '_1_9245',\n",
       " '15_4462',\n",
       " '12_8287',\n",
       " '0_3587',\n",
       " '9_6508',\n",
       " '6_5674',\n",
       " '5_1726',\n",
       " '3_1345',\n",
       " '29_4547',\n",
       " '31_4045',\n",
       " '2_8279',\n",
       " '15_6599',\n",
       " '8_3307',\n",
       " '_5_6011',\n",
       " '19_0614',\n",
       " '11_2663',\n",
       " '8_6989',\n",
       " '8_3694',\n",
       " '11_5659',\n",
       " '_16_4727',\n",
       " '4_0288',\n",
       " '17_9244',\n",
       " '18_5177',\n",
       " '10_78',\n",
       " '9_0056',\n",
       " '16_6964',\n",
       " '10_4838',\n",
       " '1_6573',\n",
       " '12_1749',\n",
       " '_13_1324',\n",
       " '17_6054',\n",
       " '11_5423',\n",
       " '15_4576',\n",
       " '5_3133',\n",
       " '3_6159',\n",
       " '5_0384',\n",
       " '6_676',\n",
       " '12_6644',\n",
       " '2_7004',\n",
       " '_0_6975',\n",
       " '9_5981',\n",
       " '5_4879',\n",
       " '_4_7645',\n",
       " '_8_4254',\n",
       " '20_8773',\n",
       " '3_1531',\n",
       " '18_5618',\n",
       " '7_7423',\n",
       " '_10_1245',\n",
       " '13_7241',\n",
       " '_3_5189',\n",
       " '1_7202',\n",
       " '_8_4051',\n",
       " '9_0164',\n",
       " '3_0657',\n",
       " '14_3691',\n",
       " '25_8398',\n",
       " '5_8764',\n",
       " '11_8411',\n",
       " '_19_7159',\n",
       " '17_5743',\n",
       " '0_5857',\n",
       " '4_4354',\n",
       " '3_9642',\n",
       " '3_1364',\n",
       " '1_6909999999999998',\n",
       " '18_5227',\n",
       " '_2_3978',\n",
       " '7_8784',\n",
       " '8_5635',\n",
       " '12_7803',\n",
       " '_1_0914']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if False:\n",
    "    def to_texts(row):\n",
    "        return [str(r).replace(\"-\",\"_\").replace(\".\",\"_\") for r in row]\n",
    "\n",
    "    all_df = pd.concat([train[feature_cols], test[feature_cols]], axis=0).reset_index(drop=True)\n",
    "    all_texts = all_df.progress_apply(to_texts, axis=1)\n",
    "    all_texts = list(all_texts)\n",
    "    pd.to_pickle(all_texts, 'cat2vec_data/all_texts.pkl')\n",
    "else:\n",
    "    all_texts = pd.read_pickle('cat2vec_data/all_texts.pkl')\n",
    "    \n",
    "all_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from random import shuffle\n",
    "    from copy import deepcopy as cp\n",
    "\n",
    "    shuffled_all_texts = cp(all_texts)\n",
    "    for r in tqdm(shuffled_all_texts):\n",
    "        shuffle(r)\n",
    "    pd.to_pickle(shuffled_all_texts, 'cat2vec_data/shuffled_all_texts.pkl')\n",
    "\n",
    "    shuffled_all_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom gensim.models.word2vec import Word2Vec\\ndim = 30\\nw2v = Word2Vec(shuffled_all_texts, size=dim, window=20, min_count=5, iter=3, sg=1, hs=1, workers=2) # skip-gram\\npickle.dump(w2v, open('cat2vec models/st_cat2vec_w2v_md_sg_v1', 'wb'))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trained on gcp multi-core server...\n",
    "'''\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "dim = 30\n",
    "w2v = Word2Vec(shuffled_all_texts, size=dim, window=20, min_count=5, iter=3, sg=1, hs=1, workers=2) # skip-gram\n",
    "pickle.dump(w2v, open('cat2vec models/st_cat2vec_w2v_md_sg_v1', 'wb'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare cat2vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "400000it [04:29, 1484.22it/s]\n"
     ]
    }
   ],
   "source": [
    "w2v = pickle.load(open('cat2vec models/st_cat2vec_w2v_md_sg_v2', 'rb'))\n",
    "cat2vec_feats = np.zeros((len(all_texts), 30*len(all_texts[0])), dtype=np.float32)\n",
    "\n",
    "for i, row in tqdm(enumerate(all_texts)):\n",
    "    for j, r in enumerate(row):\n",
    "        if r in w2v.wv:\n",
    "            cat2vec_feats[i, j*30:(j+1)*30] = w2v.wv[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005707"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cat2vec_feats==0).sum()/(len(all_texts)*30*len(all_texts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    pd.to_pickle(cat2vec_feats[:train.shape[0]], 'cat2vec_data/cat2vec_feat_train2.pkl')\n",
    "    pd.to_pickle(cat2vec_feats[train.shape[0]:], 'cat2vec_data/cat2vec_feat_test2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA to reduce dimensions\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# when copy=False, must use fit transform directly\n",
    "cat2vec_feats = PCA(n_components=100, svd_solver='arpack', random_state=0, copy=False).fit_transform(cat2vec_feats) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat2vec_feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    pd.to_pickle(cat2vec_feats[:train.shape[0]], 'cat2vec_data/cat2vec_feat_pca_train2.pkl')\n",
    "    pd.to_pickle(cat2vec_feats[train.shape[0]:], 'cat2vec_data/cat2vec_feat_pca_test2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
