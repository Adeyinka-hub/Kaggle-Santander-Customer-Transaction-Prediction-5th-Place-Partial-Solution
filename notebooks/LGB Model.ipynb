{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('data/train_original.pkl')\n",
    "test = pd.read_pickle('data/test_original.pkl')\n",
    "special_cols = [col for col in train.columns if train[col].dtype != np.float64]\n",
    "feature_cols = [col for col in train.columns if col not in special_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "'''\n",
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(x1.shape[1]):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y\n",
    "'''\n",
    "\n",
    "def augment(x,y,t=9):\n",
    "    xs,xn = [],[]\n",
    "    feat_len = x.shape[1]//2\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(feat_len):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "            x1[:,c+feat_len] = x1[ids][:,c+feat_len]\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//9):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        ids = np.arange(x1.shape[0])\n",
    "        for c in range(feat_len):\n",
    "            np.random.shuffle(ids)\n",
    "            x1[:,c] = x1[ids][:,c]\n",
    "            x1[:,c+feat_len] = x1[ids][:,c+feat_len]\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y\n",
    "\n",
    "def transform_freq_feature(df1,df2,df3_base,feat):\n",
    "    val1=df1[feat].values\n",
    "    val2=df3_base[feat].values\n",
    "    \n",
    "    defa1=defaultdict(lambda:0)\n",
    "    \n",
    "    for val in val1:\n",
    "        defa1[str(val)]+=1.\n",
    "    for val in val2:\n",
    "        defa1[str(val)]+=1.  \n",
    "        \n",
    "    df1[feat +\"_freq\"]= df1[feat].apply(lambda x :defa1[str(x)] ) \n",
    "    df2[feat+\"_freq\"]= df2[feat].apply(lambda x :defa1[str(x)] )  \n",
    "    \n",
    "def transform_gmm_feature(df1,df2,df3_base,feat):\n",
    "    vals = df1[feat].append(df3_base[feat]).values\n",
    "    gm = GaussianMixture(n_components=2)\n",
    "    gm.fit(vals.reshape((-1,1)))\n",
    "        \n",
    "    df1[feat +\"_gmm_prob\"] = gm.predict_proba(df1[[feat]].values)[:,0]\n",
    "    df2[feat+\"_gmm_prob\"]= gm.predict_proba(df2[[feat]].values)[:,0]\n",
    "    \n",
    "def load_data():\n",
    "    train_df = train[feature_cols].copy()\n",
    "    test_df = test[feature_cols].copy()\n",
    "    real_test_df = test[feature_cols].copy()\n",
    "\n",
    "    unique_samples = []\n",
    "    unique_count = np.zeros_like(test_df)\n",
    "    for feature in tqdm(range(test_df.shape[1])):\n",
    "        _, index_, count_ = np.unique(test_df.values[:, feature], return_counts=True, return_index=True)\n",
    "        unique_count[index_[count_ == 1], feature] += 1\n",
    "    \n",
    "    # Samples which have unique values are real the others are fake\n",
    "    real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "    synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "    \n",
    "    real_test_df=real_test_df.iloc[real_samples_indexes]\n",
    "    print(real_test_df.shape[0])\n",
    "    print(len(synthetic_samples_indexes))\n",
    "    \n",
    "    columns=train_df.columns.values\n",
    "    for col in tqdm(columns):\n",
    "        transform_freq_feature(train_df,test_df,real_test_df,col)\n",
    "    \n",
    "    '''\n",
    "    for f in tqdm(feature_cols[:200]): # transform into probability\n",
    "        train_df[f] = 1/(1+np.exp(-train_df[f]))\n",
    "        test_df[f] = 1/(1+np.exp(-test_df[f]))\n",
    "    '''    \n",
    "    from sklearn.preprocessing import QuantileTransformer, MinMaxScaler\n",
    "    \n",
    "    '''\n",
    "    for f in tqdm(feature_cols): # process for non-unique\n",
    "        qt = MinMaxScaler(feature_range=(-3, 3)) #QuantileTransformer(output_distribution='normal')\n",
    "        qt.fit(train_df[f].append(test_df[f]).values.reshape((-1,1)))\n",
    "        train_val = qt.transform(train_df[[f]].values).reshape((-1,))\n",
    "        test_val = qt.transform(test_df[[f]].values).reshape((-1,))\n",
    "        \n",
    "        train_df[f+'_exp'] = np.where(train_df[f+'_freq']>1, 2, 1)**train_val\n",
    "        test_df[f+'_exp'] = np.where(test_df[f+'_freq']>1, 2, 1)**test_val\n",
    "        \n",
    "        #train_df[f] = np.where(train_df[f+'_freq']>1, train_df[f], np.nan) \n",
    "        #test_df[f] = np.where(test_df[f+'_freq']>1, test_df[f], np.nan)\n",
    "    '''\n",
    "    train_df = pd.concat([train_df, pd.read_pickle('features/magic_tuned_train')], axis=1)\n",
    "    test_df = pd.concat([test_df, pd.read_pickle('features/magic_tuned_test')], axis=1)\n",
    "    \n",
    "    '''\n",
    "    train_df = pd.concat([train_df,\n",
    "                          pd.read_pickle('features/poisson_prob_train.pkl')], axis=1)\n",
    "    test_df = pd.concat([test_df,\n",
    "                        pd.read_pickle('features/poisson_prob_test.pkl')], axis=1)\n",
    "    \n",
    "    for col in tqdm(columns[[6,110, 26, 146, 139, 21, 76, 174, 133, 99, 198, 109, 80, 13, 190, 148, 0, 44, 164]]):\n",
    "        transform_gmm_feature(train_df,test_df,real_test_df,col)\n",
    "    ''' \n",
    "    print(train_df.isnull().sum().sum(), test_df.isnull().sum().sum())\n",
    "    return train_df.fillna(-999), test_df.fillna(-999), real_samples_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [00:06<00:00, 32.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 200/200 [02:28<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['var_0',\n",
       " 'var_1',\n",
       " 'var_2',\n",
       " 'var_3',\n",
       " 'var_4',\n",
       " 'var_5',\n",
       " 'var_6',\n",
       " 'var_7',\n",
       " 'var_8',\n",
       " 'var_9',\n",
       " 'var_10',\n",
       " 'var_11',\n",
       " 'var_12',\n",
       " 'var_13',\n",
       " 'var_14',\n",
       " 'var_15',\n",
       " 'var_16',\n",
       " 'var_17',\n",
       " 'var_18',\n",
       " 'var_19',\n",
       " 'var_20',\n",
       " 'var_21',\n",
       " 'var_22',\n",
       " 'var_23',\n",
       " 'var_24',\n",
       " 'var_25',\n",
       " 'var_26',\n",
       " 'var_27',\n",
       " 'var_28',\n",
       " 'var_29',\n",
       " 'var_30',\n",
       " 'var_31',\n",
       " 'var_32',\n",
       " 'var_33',\n",
       " 'var_34',\n",
       " 'var_35',\n",
       " 'var_36',\n",
       " 'var_37',\n",
       " 'var_38',\n",
       " 'var_39',\n",
       " 'var_40',\n",
       " 'var_41',\n",
       " 'var_42',\n",
       " 'var_43',\n",
       " 'var_44',\n",
       " 'var_45',\n",
       " 'var_46',\n",
       " 'var_47',\n",
       " 'var_48',\n",
       " 'var_49',\n",
       " 'var_50',\n",
       " 'var_51',\n",
       " 'var_52',\n",
       " 'var_53',\n",
       " 'var_54',\n",
       " 'var_55',\n",
       " 'var_56',\n",
       " 'var_57',\n",
       " 'var_58',\n",
       " 'var_59',\n",
       " 'var_60',\n",
       " 'var_61',\n",
       " 'var_62',\n",
       " 'var_63',\n",
       " 'var_64',\n",
       " 'var_65',\n",
       " 'var_66',\n",
       " 'var_67',\n",
       " 'var_68',\n",
       " 'var_69',\n",
       " 'var_70',\n",
       " 'var_71',\n",
       " 'var_72',\n",
       " 'var_73',\n",
       " 'var_74',\n",
       " 'var_75',\n",
       " 'var_76',\n",
       " 'var_77',\n",
       " 'var_78',\n",
       " 'var_79',\n",
       " 'var_80',\n",
       " 'var_81',\n",
       " 'var_82',\n",
       " 'var_83',\n",
       " 'var_84',\n",
       " 'var_85',\n",
       " 'var_86',\n",
       " 'var_87',\n",
       " 'var_88',\n",
       " 'var_89',\n",
       " 'var_90',\n",
       " 'var_91',\n",
       " 'var_92',\n",
       " 'var_93',\n",
       " 'var_94',\n",
       " 'var_95',\n",
       " 'var_96',\n",
       " 'var_97',\n",
       " 'var_98',\n",
       " 'var_99',\n",
       " 'var_100',\n",
       " 'var_101',\n",
       " 'var_102',\n",
       " 'var_103',\n",
       " 'var_104',\n",
       " 'var_105',\n",
       " 'var_106',\n",
       " 'var_107',\n",
       " 'var_108',\n",
       " 'var_109',\n",
       " 'var_110',\n",
       " 'var_111',\n",
       " 'var_112',\n",
       " 'var_113',\n",
       " 'var_114',\n",
       " 'var_115',\n",
       " 'var_116',\n",
       " 'var_117',\n",
       " 'var_118',\n",
       " 'var_119',\n",
       " 'var_120',\n",
       " 'var_121',\n",
       " 'var_122',\n",
       " 'var_123',\n",
       " 'var_124',\n",
       " 'var_125',\n",
       " 'var_126',\n",
       " 'var_127',\n",
       " 'var_128',\n",
       " 'var_129',\n",
       " 'var_130',\n",
       " 'var_131',\n",
       " 'var_132',\n",
       " 'var_133',\n",
       " 'var_134',\n",
       " 'var_135',\n",
       " 'var_136',\n",
       " 'var_137',\n",
       " 'var_138',\n",
       " 'var_139',\n",
       " 'var_140',\n",
       " 'var_141',\n",
       " 'var_142',\n",
       " 'var_143',\n",
       " 'var_144',\n",
       " 'var_145',\n",
       " 'var_146',\n",
       " 'var_147',\n",
       " 'var_148',\n",
       " 'var_149',\n",
       " 'var_150',\n",
       " 'var_151',\n",
       " 'var_152',\n",
       " 'var_153',\n",
       " 'var_154',\n",
       " 'var_155',\n",
       " 'var_156',\n",
       " 'var_157',\n",
       " 'var_158',\n",
       " 'var_159',\n",
       " 'var_160',\n",
       " 'var_161',\n",
       " 'var_162',\n",
       " 'var_163',\n",
       " 'var_164',\n",
       " 'var_165',\n",
       " 'var_166',\n",
       " 'var_167',\n",
       " 'var_168',\n",
       " 'var_169',\n",
       " 'var_170',\n",
       " 'var_171',\n",
       " 'var_172',\n",
       " 'var_173',\n",
       " 'var_174',\n",
       " 'var_175',\n",
       " 'var_176',\n",
       " 'var_177',\n",
       " 'var_178',\n",
       " 'var_179',\n",
       " 'var_180',\n",
       " 'var_181',\n",
       " 'var_182',\n",
       " 'var_183',\n",
       " 'var_184',\n",
       " 'var_185',\n",
       " 'var_186',\n",
       " 'var_187',\n",
       " 'var_188',\n",
       " 'var_189',\n",
       " 'var_190',\n",
       " 'var_191',\n",
       " 'var_192',\n",
       " 'var_193',\n",
       " 'var_194',\n",
       " 'var_195',\n",
       " 'var_196',\n",
       " 'var_197',\n",
       " 'var_198',\n",
       " 'var_199',\n",
       " 'var_0_freq',\n",
       " 'var_1_freq',\n",
       " 'var_2_freq',\n",
       " 'var_3_freq',\n",
       " 'var_4_freq',\n",
       " 'var_5_freq',\n",
       " 'var_6_freq',\n",
       " 'var_7_freq',\n",
       " 'var_8_freq',\n",
       " 'var_9_freq',\n",
       " 'var_10_freq',\n",
       " 'var_11_freq',\n",
       " 'var_12_freq',\n",
       " 'var_13_freq',\n",
       " 'var_14_freq',\n",
       " 'var_15_freq',\n",
       " 'var_16_freq',\n",
       " 'var_17_freq',\n",
       " 'var_18_freq',\n",
       " 'var_19_freq',\n",
       " 'var_20_freq',\n",
       " 'var_21_freq',\n",
       " 'var_22_freq',\n",
       " 'var_23_freq',\n",
       " 'var_24_freq',\n",
       " 'var_25_freq',\n",
       " 'var_26_freq',\n",
       " 'var_27_freq',\n",
       " 'var_28_freq',\n",
       " 'var_29_freq',\n",
       " 'var_30_freq',\n",
       " 'var_31_freq',\n",
       " 'var_32_freq',\n",
       " 'var_33_freq',\n",
       " 'var_34_freq',\n",
       " 'var_35_freq',\n",
       " 'var_36_freq',\n",
       " 'var_37_freq',\n",
       " 'var_38_freq',\n",
       " 'var_39_freq',\n",
       " 'var_40_freq',\n",
       " 'var_41_freq',\n",
       " 'var_42_freq',\n",
       " 'var_43_freq',\n",
       " 'var_44_freq',\n",
       " 'var_45_freq',\n",
       " 'var_46_freq',\n",
       " 'var_47_freq',\n",
       " 'var_48_freq',\n",
       " 'var_49_freq',\n",
       " 'var_50_freq',\n",
       " 'var_51_freq',\n",
       " 'var_52_freq',\n",
       " 'var_53_freq',\n",
       " 'var_54_freq',\n",
       " 'var_55_freq',\n",
       " 'var_56_freq',\n",
       " 'var_57_freq',\n",
       " 'var_58_freq',\n",
       " 'var_59_freq',\n",
       " 'var_60_freq',\n",
       " 'var_61_freq',\n",
       " 'var_62_freq',\n",
       " 'var_63_freq',\n",
       " 'var_64_freq',\n",
       " 'var_65_freq',\n",
       " 'var_66_freq',\n",
       " 'var_67_freq',\n",
       " 'var_68_freq',\n",
       " 'var_69_freq',\n",
       " 'var_70_freq',\n",
       " 'var_71_freq',\n",
       " 'var_72_freq',\n",
       " 'var_73_freq',\n",
       " 'var_74_freq',\n",
       " 'var_75_freq',\n",
       " 'var_76_freq',\n",
       " 'var_77_freq',\n",
       " 'var_78_freq',\n",
       " 'var_79_freq',\n",
       " 'var_80_freq',\n",
       " 'var_81_freq',\n",
       " 'var_82_freq',\n",
       " 'var_83_freq',\n",
       " 'var_84_freq',\n",
       " 'var_85_freq',\n",
       " 'var_86_freq',\n",
       " 'var_87_freq',\n",
       " 'var_88_freq',\n",
       " 'var_89_freq',\n",
       " 'var_90_freq',\n",
       " 'var_91_freq',\n",
       " 'var_92_freq',\n",
       " 'var_93_freq',\n",
       " 'var_94_freq',\n",
       " 'var_95_freq',\n",
       " 'var_96_freq',\n",
       " 'var_97_freq',\n",
       " 'var_98_freq',\n",
       " 'var_99_freq',\n",
       " 'var_100_freq',\n",
       " 'var_101_freq',\n",
       " 'var_102_freq',\n",
       " 'var_103_freq',\n",
       " 'var_104_freq',\n",
       " 'var_105_freq',\n",
       " 'var_106_freq',\n",
       " 'var_107_freq',\n",
       " 'var_108_freq',\n",
       " 'var_109_freq',\n",
       " 'var_110_freq',\n",
       " 'var_111_freq',\n",
       " 'var_112_freq',\n",
       " 'var_113_freq',\n",
       " 'var_114_freq',\n",
       " 'var_115_freq',\n",
       " 'var_116_freq',\n",
       " 'var_117_freq',\n",
       " 'var_118_freq',\n",
       " 'var_119_freq',\n",
       " 'var_120_freq',\n",
       " 'var_121_freq',\n",
       " 'var_122_freq',\n",
       " 'var_123_freq',\n",
       " 'var_124_freq',\n",
       " 'var_125_freq',\n",
       " 'var_126_freq',\n",
       " 'var_127_freq',\n",
       " 'var_128_freq',\n",
       " 'var_129_freq',\n",
       " 'var_130_freq',\n",
       " 'var_131_freq',\n",
       " 'var_132_freq',\n",
       " 'var_133_freq',\n",
       " 'var_134_freq',\n",
       " 'var_135_freq',\n",
       " 'var_136_freq',\n",
       " 'var_137_freq',\n",
       " 'var_138_freq',\n",
       " 'var_139_freq',\n",
       " 'var_140_freq',\n",
       " 'var_141_freq',\n",
       " 'var_142_freq',\n",
       " 'var_143_freq',\n",
       " 'var_144_freq',\n",
       " 'var_145_freq',\n",
       " 'var_146_freq',\n",
       " 'var_147_freq',\n",
       " 'var_148_freq',\n",
       " 'var_149_freq',\n",
       " 'var_150_freq',\n",
       " 'var_151_freq',\n",
       " 'var_152_freq',\n",
       " 'var_153_freq',\n",
       " 'var_154_freq',\n",
       " 'var_155_freq',\n",
       " 'var_156_freq',\n",
       " 'var_157_freq',\n",
       " 'var_158_freq',\n",
       " 'var_159_freq',\n",
       " 'var_160_freq',\n",
       " 'var_161_freq',\n",
       " 'var_162_freq',\n",
       " 'var_163_freq',\n",
       " 'var_164_freq',\n",
       " 'var_165_freq',\n",
       " 'var_166_freq',\n",
       " 'var_167_freq',\n",
       " 'var_168_freq',\n",
       " 'var_169_freq',\n",
       " 'var_170_freq',\n",
       " 'var_171_freq',\n",
       " 'var_172_freq',\n",
       " 'var_173_freq',\n",
       " 'var_174_freq',\n",
       " 'var_175_freq',\n",
       " 'var_176_freq',\n",
       " 'var_177_freq',\n",
       " 'var_178_freq',\n",
       " 'var_179_freq',\n",
       " 'var_180_freq',\n",
       " 'var_181_freq',\n",
       " 'var_182_freq',\n",
       " 'var_183_freq',\n",
       " 'var_184_freq',\n",
       " 'var_185_freq',\n",
       " 'var_186_freq',\n",
       " 'var_187_freq',\n",
       " 'var_188_freq',\n",
       " 'var_189_freq',\n",
       " 'var_190_freq',\n",
       " 'var_191_freq',\n",
       " 'var_192_freq',\n",
       " 'var_193_freq',\n",
       " 'var_194_freq',\n",
       " 'var_195_freq',\n",
       " 'var_196_freq',\n",
       " 'var_197_freq',\n",
       " 'var_198_freq',\n",
       " 'var_199_freq',\n",
       " 'var_0_exp',\n",
       " 'var_1_exp',\n",
       " 'var_2_exp',\n",
       " 'var_3_exp',\n",
       " 'var_4_exp',\n",
       " 'var_5_exp',\n",
       " 'var_6_exp',\n",
       " 'var_7_exp',\n",
       " 'var_8_exp',\n",
       " 'var_9_exp',\n",
       " 'var_10_exp',\n",
       " 'var_11_exp',\n",
       " 'var_12_exp',\n",
       " 'var_13_exp',\n",
       " 'var_14_exp',\n",
       " 'var_15_exp',\n",
       " 'var_16_exp',\n",
       " 'var_17_exp',\n",
       " 'var_18_exp',\n",
       " 'var_19_exp',\n",
       " 'var_20_exp',\n",
       " 'var_21_exp',\n",
       " 'var_22_exp',\n",
       " 'var_23_exp',\n",
       " 'var_24_exp',\n",
       " 'var_25_exp',\n",
       " 'var_26_exp',\n",
       " 'var_27_exp',\n",
       " 'var_28_exp',\n",
       " 'var_29_exp',\n",
       " 'var_30_exp',\n",
       " 'var_31_exp',\n",
       " 'var_32_exp',\n",
       " 'var_33_exp',\n",
       " 'var_34_exp',\n",
       " 'var_35_exp',\n",
       " 'var_36_exp',\n",
       " 'var_37_exp',\n",
       " 'var_38_exp',\n",
       " 'var_39_exp',\n",
       " 'var_40_exp',\n",
       " 'var_41_exp',\n",
       " 'var_42_exp',\n",
       " 'var_43_exp',\n",
       " 'var_44_exp',\n",
       " 'var_45_exp',\n",
       " 'var_46_exp',\n",
       " 'var_47_exp',\n",
       " 'var_48_exp',\n",
       " 'var_49_exp',\n",
       " 'var_50_exp',\n",
       " 'var_51_exp',\n",
       " 'var_52_exp',\n",
       " 'var_53_exp',\n",
       " 'var_54_exp',\n",
       " 'var_55_exp',\n",
       " 'var_56_exp',\n",
       " 'var_57_exp',\n",
       " 'var_58_exp',\n",
       " 'var_59_exp',\n",
       " 'var_60_exp',\n",
       " 'var_61_exp',\n",
       " 'var_62_exp',\n",
       " 'var_63_exp',\n",
       " 'var_64_exp',\n",
       " 'var_65_exp',\n",
       " 'var_66_exp',\n",
       " 'var_67_exp',\n",
       " 'var_68_exp',\n",
       " 'var_69_exp',\n",
       " 'var_70_exp',\n",
       " 'var_71_exp',\n",
       " 'var_72_exp',\n",
       " 'var_73_exp',\n",
       " 'var_74_exp',\n",
       " 'var_75_exp',\n",
       " 'var_76_exp',\n",
       " 'var_77_exp',\n",
       " 'var_78_exp',\n",
       " 'var_79_exp',\n",
       " 'var_80_exp',\n",
       " 'var_81_exp',\n",
       " 'var_82_exp',\n",
       " 'var_83_exp',\n",
       " 'var_84_exp',\n",
       " 'var_85_exp',\n",
       " 'var_86_exp',\n",
       " 'var_87_exp',\n",
       " 'var_88_exp',\n",
       " 'var_89_exp',\n",
       " 'var_90_exp',\n",
       " 'var_91_exp',\n",
       " 'var_92_exp',\n",
       " 'var_93_exp',\n",
       " 'var_94_exp',\n",
       " 'var_95_exp',\n",
       " 'var_96_exp',\n",
       " 'var_97_exp',\n",
       " 'var_98_exp',\n",
       " 'var_99_exp',\n",
       " 'var_100_exp',\n",
       " 'var_101_exp',\n",
       " 'var_102_exp',\n",
       " 'var_103_exp',\n",
       " 'var_104_exp',\n",
       " 'var_105_exp',\n",
       " 'var_106_exp',\n",
       " 'var_107_exp',\n",
       " 'var_108_exp',\n",
       " 'var_109_exp',\n",
       " 'var_110_exp',\n",
       " 'var_111_exp',\n",
       " 'var_112_exp',\n",
       " 'var_113_exp',\n",
       " 'var_114_exp',\n",
       " 'var_115_exp',\n",
       " 'var_116_exp',\n",
       " 'var_117_exp',\n",
       " 'var_118_exp',\n",
       " 'var_119_exp',\n",
       " 'var_120_exp',\n",
       " 'var_121_exp',\n",
       " 'var_122_exp',\n",
       " 'var_123_exp',\n",
       " 'var_124_exp',\n",
       " 'var_125_exp',\n",
       " 'var_126_exp',\n",
       " 'var_127_exp',\n",
       " 'var_128_exp',\n",
       " 'var_129_exp',\n",
       " 'var_130_exp',\n",
       " 'var_131_exp',\n",
       " 'var_132_exp',\n",
       " 'var_133_exp',\n",
       " 'var_134_exp',\n",
       " 'var_135_exp',\n",
       " 'var_136_exp',\n",
       " 'var_137_exp',\n",
       " 'var_138_exp',\n",
       " 'var_139_exp',\n",
       " 'var_140_exp',\n",
       " 'var_141_exp',\n",
       " 'var_142_exp',\n",
       " 'var_143_exp',\n",
       " 'var_144_exp',\n",
       " 'var_145_exp',\n",
       " 'var_146_exp',\n",
       " 'var_147_exp',\n",
       " 'var_148_exp',\n",
       " 'var_149_exp',\n",
       " 'var_150_exp',\n",
       " 'var_151_exp',\n",
       " 'var_152_exp',\n",
       " 'var_153_exp',\n",
       " 'var_154_exp',\n",
       " 'var_155_exp',\n",
       " 'var_156_exp',\n",
       " 'var_157_exp',\n",
       " 'var_158_exp',\n",
       " 'var_159_exp',\n",
       " 'var_160_exp',\n",
       " 'var_161_exp',\n",
       " 'var_162_exp',\n",
       " 'var_163_exp',\n",
       " 'var_164_exp',\n",
       " 'var_165_exp',\n",
       " 'var_166_exp',\n",
       " 'var_167_exp',\n",
       " 'var_168_exp',\n",
       " 'var_169_exp',\n",
       " 'var_170_exp',\n",
       " 'var_171_exp',\n",
       " 'var_172_exp',\n",
       " 'var_173_exp',\n",
       " 'var_174_exp',\n",
       " 'var_175_exp',\n",
       " 'var_176_exp',\n",
       " 'var_177_exp',\n",
       " 'var_178_exp',\n",
       " 'var_179_exp',\n",
       " 'var_180_exp',\n",
       " 'var_181_exp',\n",
       " 'var_182_exp',\n",
       " 'var_183_exp',\n",
       " 'var_184_exp',\n",
       " 'var_185_exp',\n",
       " 'var_186_exp',\n",
       " 'var_187_exp',\n",
       " 'var_188_exp',\n",
       " 'var_189_exp',\n",
       " 'var_190_exp',\n",
       " 'var_191_exp',\n",
       " 'var_192_exp',\n",
       " 'var_193_exp',\n",
       " 'var_194_exp',\n",
       " 'var_195_exp',\n",
       " 'var_196_exp',\n",
       " 'var_197_exp',\n",
       " 'var_198_exp',\n",
       " 'var_199_exp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, test_df, real_samples_indexes = load_data()\n",
    "train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Mon Apr  8 19:47:18 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.839297\tvalid_1's auc: 0.824869\n",
      "[200]\ttraining's auc: 0.872465\tvalid_1's auc: 0.85341\n",
      "[300]\ttraining's auc: 0.889264\tvalid_1's auc: 0.868275\n",
      "[400]\ttraining's auc: 0.901068\tvalid_1's auc: 0.878591\n",
      "[500]\ttraining's auc: 0.909811\tvalid_1's auc: 0.885862\n",
      "[600]\ttraining's auc: 0.916242\tvalid_1's auc: 0.891443\n",
      "[700]\ttraining's auc: 0.921588\tvalid_1's auc: 0.895391\n",
      "[800]\ttraining's auc: 0.925786\tvalid_1's auc: 0.898593\n",
      "[900]\ttraining's auc: 0.929179\tvalid_1's auc: 0.901113\n",
      "[1000]\ttraining's auc: 0.932161\tvalid_1's auc: 0.90335\n",
      "[1100]\ttraining's auc: 0.934712\tvalid_1's auc: 0.905116\n",
      "[1200]\ttraining's auc: 0.93704\tvalid_1's auc: 0.906651\n",
      "[1300]\ttraining's auc: 0.939065\tvalid_1's auc: 0.907955\n",
      "[1400]\ttraining's auc: 0.940892\tvalid_1's auc: 0.909261\n",
      "[1500]\ttraining's auc: 0.942483\tvalid_1's auc: 0.910342\n",
      "[1600]\ttraining's auc: 0.943945\tvalid_1's auc: 0.911243\n",
      "[1700]\ttraining's auc: 0.945169\tvalid_1's auc: 0.911752\n",
      "[1800]\ttraining's auc: 0.946437\tvalid_1's auc: 0.912548\n",
      "[1900]\ttraining's auc: 0.947479\tvalid_1's auc: 0.913081\n",
      "[2000]\ttraining's auc: 0.94859\tvalid_1's auc: 0.913488\n",
      "[2100]\ttraining's auc: 0.949578\tvalid_1's auc: 0.913938\n",
      "[2200]\ttraining's auc: 0.950584\tvalid_1's auc: 0.914353\n",
      "[2300]\ttraining's auc: 0.951521\tvalid_1's auc: 0.914665\n",
      "[2400]\ttraining's auc: 0.952519\tvalid_1's auc: 0.914981\n",
      "[2500]\ttraining's auc: 0.953389\tvalid_1's auc: 0.915239\n",
      "[2600]\ttraining's auc: 0.954282\tvalid_1's auc: 0.915371\n",
      "[2700]\ttraining's auc: 0.955106\tvalid_1's auc: 0.915517\n",
      "[2800]\ttraining's auc: 0.955967\tvalid_1's auc: 0.915625\n",
      "[2900]\ttraining's auc: 0.95679\tvalid_1's auc: 0.915776\n",
      "[3000]\ttraining's auc: 0.957595\tvalid_1's auc: 0.915974\n",
      "[3100]\ttraining's auc: 0.958433\tvalid_1's auc: 0.916013\n",
      "[3200]\ttraining's auc: 0.959257\tvalid_1's auc: 0.916116\n",
      "[3300]\ttraining's auc: 0.960072\tvalid_1's auc: 0.916194\n",
      "[3400]\ttraining's auc: 0.960872\tvalid_1's auc: 0.916233\n",
      "[3500]\ttraining's auc: 0.961672\tvalid_1's auc: 0.91623\n",
      "[3600]\ttraining's auc: 0.962449\tvalid_1's auc: 0.916235\n",
      "[3700]\ttraining's auc: 0.96317\tvalid_1's auc: 0.91627\n",
      "[3800]\ttraining's auc: 0.963923\tvalid_1's auc: 0.916343\n",
      "[3900]\ttraining's auc: 0.964631\tvalid_1's auc: 0.916334\n",
      "[4000]\ttraining's auc: 0.965367\tvalid_1's auc: 0.91634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4000]\ttraining's auc: 0.965367\tvalid_1's auc: 0.91634\n",
      "0.9163403046142125\n",
      "Fold 1 started at Mon Apr  8 19:57:15 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.83764\tvalid_1's auc: 0.818396\n",
      "[200]\ttraining's auc: 0.870955\tvalid_1's auc: 0.849837\n",
      "[300]\ttraining's auc: 0.888622\tvalid_1's auc: 0.865325\n",
      "[400]\ttraining's auc: 0.900734\tvalid_1's auc: 0.875919\n",
      "[500]\ttraining's auc: 0.909453\tvalid_1's auc: 0.883667\n",
      "[600]\ttraining's auc: 0.916336\tvalid_1's auc: 0.889364\n",
      "[700]\ttraining's auc: 0.921206\tvalid_1's auc: 0.893562\n",
      "[800]\ttraining's auc: 0.925405\tvalid_1's auc: 0.896993\n",
      "[900]\ttraining's auc: 0.928858\tvalid_1's auc: 0.900006\n",
      "[1000]\ttraining's auc: 0.931762\tvalid_1's auc: 0.902236\n",
      "[1100]\ttraining's auc: 0.934391\tvalid_1's auc: 0.904222\n",
      "[1200]\ttraining's auc: 0.936553\tvalid_1's auc: 0.905967\n",
      "[1300]\ttraining's auc: 0.93866\tvalid_1's auc: 0.907532\n",
      "[1400]\ttraining's auc: 0.940468\tvalid_1's auc: 0.908857\n",
      "[1500]\ttraining's auc: 0.942127\tvalid_1's auc: 0.910003\n",
      "[1600]\ttraining's auc: 0.943479\tvalid_1's auc: 0.910953\n",
      "[1700]\ttraining's auc: 0.944835\tvalid_1's auc: 0.911751\n",
      "[1800]\ttraining's auc: 0.946097\tvalid_1's auc: 0.912505\n",
      "[1900]\ttraining's auc: 0.947208\tvalid_1's auc: 0.913167\n",
      "[2000]\ttraining's auc: 0.948217\tvalid_1's auc: 0.913671\n",
      "[2100]\ttraining's auc: 0.949233\tvalid_1's auc: 0.91414\n",
      "[2200]\ttraining's auc: 0.950267\tvalid_1's auc: 0.914454\n",
      "[2300]\ttraining's auc: 0.951213\tvalid_1's auc: 0.914791\n",
      "[2400]\ttraining's auc: 0.952134\tvalid_1's auc: 0.915038\n",
      "[2500]\ttraining's auc: 0.953016\tvalid_1's auc: 0.915329\n",
      "[2600]\ttraining's auc: 0.953961\tvalid_1's auc: 0.915578\n",
      "[2700]\ttraining's auc: 0.954798\tvalid_1's auc: 0.915792\n",
      "[2800]\ttraining's auc: 0.955566\tvalid_1's auc: 0.915909\n",
      "[2900]\ttraining's auc: 0.956402\tvalid_1's auc: 0.916043\n",
      "[3000]\ttraining's auc: 0.957183\tvalid_1's auc: 0.916172\n",
      "[3100]\ttraining's auc: 0.958041\tvalid_1's auc: 0.916312\n",
      "[3200]\ttraining's auc: 0.958914\tvalid_1's auc: 0.916458\n",
      "[3300]\ttraining's auc: 0.959731\tvalid_1's auc: 0.916562\n",
      "[3400]\ttraining's auc: 0.960571\tvalid_1's auc: 0.916629\n",
      "[3500]\ttraining's auc: 0.961363\tvalid_1's auc: 0.916679\n",
      "[3600]\ttraining's auc: 0.962102\tvalid_1's auc: 0.916723\n",
      "[3700]\ttraining's auc: 0.962891\tvalid_1's auc: 0.916701\n",
      "[3800]\ttraining's auc: 0.963643\tvalid_1's auc: 0.916669\n",
      "Early stopping, best iteration is:\n",
      "[3637]\ttraining's auc: 0.962377\tvalid_1's auc: 0.916743\n",
      "0.9167429125786244\n",
      "Fold 2 started at Mon Apr  8 20:06:32 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.838534\tvalid_1's auc: 0.825071\n",
      "[200]\ttraining's auc: 0.871185\tvalid_1's auc: 0.855526\n",
      "[300]\ttraining's auc: 0.88809\tvalid_1's auc: 0.870343\n",
      "[400]\ttraining's auc: 0.899958\tvalid_1's auc: 0.881175\n",
      "[500]\ttraining's auc: 0.908589\tvalid_1's auc: 0.888476\n",
      "[600]\ttraining's auc: 0.915461\tvalid_1's auc: 0.894629\n",
      "[700]\ttraining's auc: 0.920674\tvalid_1's auc: 0.898929\n",
      "[800]\ttraining's auc: 0.925006\tvalid_1's auc: 0.902467\n",
      "[900]\ttraining's auc: 0.928596\tvalid_1's auc: 0.905036\n",
      "[1000]\ttraining's auc: 0.931477\tvalid_1's auc: 0.907185\n",
      "[1100]\ttraining's auc: 0.934068\tvalid_1's auc: 0.909344\n",
      "[1200]\ttraining's auc: 0.936334\tvalid_1's auc: 0.910885\n",
      "[1300]\ttraining's auc: 0.938275\tvalid_1's auc: 0.912149\n",
      "[1400]\ttraining's auc: 0.94002\tvalid_1's auc: 0.913317\n",
      "[1500]\ttraining's auc: 0.941459\tvalid_1's auc: 0.91421\n",
      "[1600]\ttraining's auc: 0.942989\tvalid_1's auc: 0.915224\n",
      "[1700]\ttraining's auc: 0.944277\tvalid_1's auc: 0.915998\n",
      "[1800]\ttraining's auc: 0.945488\tvalid_1's auc: 0.916655\n",
      "[1900]\ttraining's auc: 0.946604\tvalid_1's auc: 0.917196\n",
      "[2000]\ttraining's auc: 0.947704\tvalid_1's auc: 0.917734\n",
      "[2100]\ttraining's auc: 0.948848\tvalid_1's auc: 0.918257\n",
      "[2200]\ttraining's auc: 0.949804\tvalid_1's auc: 0.918566\n",
      "[2300]\ttraining's auc: 0.950693\tvalid_1's auc: 0.918913\n",
      "[2400]\ttraining's auc: 0.951625\tvalid_1's auc: 0.919251\n",
      "[2500]\ttraining's auc: 0.952568\tvalid_1's auc: 0.919526\n",
      "[2600]\ttraining's auc: 0.953452\tvalid_1's auc: 0.919676\n",
      "[2700]\ttraining's auc: 0.954293\tvalid_1's auc: 0.919756\n",
      "[2800]\ttraining's auc: 0.955234\tvalid_1's auc: 0.919864\n",
      "[2900]\ttraining's auc: 0.956059\tvalid_1's auc: 0.920004\n",
      "[3000]\ttraining's auc: 0.956931\tvalid_1's auc: 0.920176\n",
      "[3100]\ttraining's auc: 0.957734\tvalid_1's auc: 0.920326\n",
      "[3200]\ttraining's auc: 0.958529\tvalid_1's auc: 0.920291\n",
      "[3300]\ttraining's auc: 0.95939\tvalid_1's auc: 0.920309\n",
      "Early stopping, best iteration is:\n",
      "[3160]\ttraining's auc: 0.958197\tvalid_1's auc: 0.920359\n",
      "0.9203592406022566\n",
      "Fold 3 started at Mon Apr  8 20:14:51 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's auc: 0.83513\tvalid_1's auc: 0.827809\n",
      "[200]\ttraining's auc: 0.869664\tvalid_1's auc: 0.859027\n",
      "[300]\ttraining's auc: 0.887282\tvalid_1's auc: 0.874253\n",
      "[400]\ttraining's auc: 0.899505\tvalid_1's auc: 0.885035\n",
      "[500]\ttraining's auc: 0.90865\tvalid_1's auc: 0.892169\n",
      "[600]\ttraining's auc: 0.915073\tvalid_1's auc: 0.8972\n",
      "[700]\ttraining's auc: 0.920482\tvalid_1's auc: 0.901054\n",
      "[800]\ttraining's auc: 0.924695\tvalid_1's auc: 0.904111\n",
      "[900]\ttraining's auc: 0.92819\tvalid_1's auc: 0.906835\n",
      "[1000]\ttraining's auc: 0.931013\tvalid_1's auc: 0.908714\n",
      "[1100]\ttraining's auc: 0.933672\tvalid_1's auc: 0.910697\n",
      "[1200]\ttraining's auc: 0.935919\tvalid_1's auc: 0.912017\n",
      "[1300]\ttraining's auc: 0.937694\tvalid_1's auc: 0.913257\n",
      "[1400]\ttraining's auc: 0.939619\tvalid_1's auc: 0.914453\n",
      "[1500]\ttraining's auc: 0.941157\tvalid_1's auc: 0.915104\n",
      "[1600]\ttraining's auc: 0.942723\tvalid_1's auc: 0.91602\n",
      "[1700]\ttraining's auc: 0.944008\tvalid_1's auc: 0.916584\n",
      "[1800]\ttraining's auc: 0.945271\tvalid_1's auc: 0.917038\n",
      "[1900]\ttraining's auc: 0.946352\tvalid_1's auc: 0.917513\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-bf4fccd0c986>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     model = lgb.train(params,train_data, num_boost_round=4000 ,\n\u001b[0;32m     46\u001b[0m                     \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m                     early_stopping_rounds = 200)\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mfold_importance_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1758\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1760\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1761\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "version = 'kh_lgb_4fold_testing'\n",
    "\n",
    "params = {'num_leaves': 8,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.03,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.7289,\n",
    "         'reg_lambda': 4.984,\n",
    "         'random_state': 42,\n",
    "         'metric': 'auc',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01,\n",
    "         'min_child_weight': 19.428,\n",
    "         'num_threads': 2}\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "prediction = np.zeros(len(test))\n",
    "\n",
    "n_fold = 4\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(train.target.values,train.target.values)):\n",
    "    \n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = train_df.loc[train_index].values, train_df.loc[valid_index].values\n",
    "    y_train, y_valid = train.target.values[train_index], train.target.values[valid_index]\n",
    "    #X_train, y_train = augment(X_train, y_train)\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,train_data, num_boost_round=4000 ,\n",
    "                    valid_sets = [train_data, valid_data], verbose_eval=100,\n",
    "                    early_stopping_rounds = 200)\n",
    "     \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = train_df.columns\n",
    "    fold_importance_df[\"importance\"] = model.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_n + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)    \n",
    "       \n",
    "    oof[valid_index] = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    prediction += model.predict(test_df.values, num_iteration=model.best_iteration)/n_fold\n",
    "    gc.collect()\n",
    "    print(roc_auc_score(y_valid, oof[valid_index]))\n",
    "    \n",
    "full_auc = roc_auc_score(train.target.values, oof)\n",
    "print(full_auc)\n",
    "# baseline: raw features 10 fold: cv: 0.8984, lb 0.899\n",
    "# kh_lgb_10fold_target_encode_ver1: cv: 0.8996, lb 0.898\n",
    "# kh_lgb_10fold_all_item_target_encode_ver1 (min samples=100) (pure new feat): cv: 0.9933 lb: 0.539\n",
    "# kh_lgb_10fold_all_item_target_encode_ver2 (min samples=500) ==> no help, cut off\n",
    "# kh_lgb_10fold_all_item_vc_encode_ver1 ==> no help, cut off\n",
    "# kh_lgb_10fold_per_day_vc_encode_ver1 (vc + le): cv: 0.9108 lb: \n",
    "# kh_lgb_10fold_per_day_vc_encode_ver2 (cumulative vc + le): cv: 0.8988 lb: \n",
    "# kh_lgb_10fold_per_day_vc_encode_ver2 (vc + pop feat): cv: 0.9108 lb: 0.900\n",
    "# kh_lgb_10fold_future_appear_cnt_v1: cv: 0.8981, lb:\n",
    "# kh_lgb_10fold_cum_encode_v1: cv: 0.995, lb: 0.693\n",
    "# kh_lgb_10fold_target_encode_ver2 (top 51 + features): cv: 0.8996, lb 0.0.897\n",
    "# kh_lgb_10fold_target_encode_by_vc_ver1: cv: 0.9071, lb:\n",
    "# kh_lgb_10fold_has_pair_ver1: cv: lb: \n",
    "# kh_lgb_10fold_pos_sum_magic_ver2: cv: 0.8982, lb:\n",
    "# kh_lgb_10fold_cumulative_vc_v1: cv: 0.8982\n",
    "# kh_lgb_10fold_by_date_freq_cnt: cv: 0.8983\n",
    "# kh_lgb_10fold_sdae_v1: cv: no help\n",
    "# kh_lgb_10fold_all_items_opposite_rank_count_encode_v1:\n",
    "# kh_lgb_10fold_per_feature_opposite_rank_count_encode_v1: cv: 0.9039, lb: 0.900\n",
    "# kh_lgb_10fold_gp_time_feats_v1: cv: 0.8977694185263893\n",
    "# kh_lgb_10fold_leaking_trend_v1: cv: no help\n",
    "# new no fake (n: 9, p: 1): cv: 0.91099\n",
    "# kh_lgb_10fold_per_feat_opposite_rank_count_diff_v2: no help\n",
    "# kh_lgb_10fold_target_corr_sum_v1: no help\n",
    "# kh_lgb_10fold_freq_aug_v1 (n: 9, p: 2): cv: 0.9153283467600679, lb: 0.916\n",
    "# kh_lgb_10fold_freq_aug_v2 (n: 9, p: 3): cv: 0.9155296211906148, lb: \n",
    "# kh_lgb_10fold_freq_aug_v3 (n: 9, p: 9): cv: 0.9162549832155663, lb: 0.917\n",
    "# kh_lgb_10fold_freq_aug_v4 (n: 18, p: 18), nround=5000: fold 1: 0.92163[4000], 0.923613[5000]: cv: lb: \n",
    "# kh_lgb_10fold_freq_aug_v5 (n: 9, p: 9), nround=5000: fold 1: 0.9220[4000], 0.923529[5000], cv: lb:\n",
    "# kh_lgb_10fold_freq_aug_v5 (n: 9, p: 12), nround=4000: cv: lb:\n",
    "# original 4 fold's 1st fold: 0.908x\n",
    "# marcus minmax 1st fold: 0.917765\n",
    "# marcus minmax, realtest only 1st fold: 0.917532\n",
    "# clip_freq* prob (1/(1+exp(-x)), 1st fold: 0.913211\n",
    "# freq** quantile(x), 1st fold: 0.913417\n",
    "# clip_freq** quantile(x), 1st fold: 0.917749\n",
    "# mark unique as np.nan: nothinng\n",
    "# marcus minmax, top 50 exp feats only, 1st fold:  0.911331\n",
    "# predict unique vals: 0.909005\n",
    "# nn per column oof raw, 1st fold: 0.908399\n",
    "# magic untune 1st fold: 0.917456\n",
    "# magic tuned 1st fold: 0.91634 (worse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(oof, 'oof+submission/'+version+'_oof_train')\n",
    "pd.to_pickle(prediction, 'oof+submission/'+version+'_oof_test')    \n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "sub[\"target\"] = prediction\n",
    "sub.to_csv('oof+submission/' + version + '_' + str(full_auc).replace('.', '_') + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows=600\n",
    "mean_gain = feature_importance_df[['importance', 'Feature']].groupby('Feature').mean().sort_values('importance', ascending=False)\n",
    "mean_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f.replace('_exp', '') for f in mean_gain.index if 'exp' in f]\n",
    "feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
