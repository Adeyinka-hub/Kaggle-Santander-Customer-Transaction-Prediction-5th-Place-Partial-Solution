{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('data/train_original.pkl')\n",
    "test = pd.read_pickle('data/test_original.pkl')\n",
    "special_cols = [col for col in train.columns if train[col].dtype != np.float64]\n",
    "feature_cols = [col for col in train.columns if col not in special_cols]\n",
    "target = train.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    from tqdm import tqdm\n",
    "    import scipy\n",
    "    \n",
    "    class GaussRankScaler():\n",
    "        def __init__( self ):\n",
    "            self.epsilon = 1e-9\n",
    "            self.lower = -1 + self.epsilon\n",
    "            self.upper =  1 - self.epsilon\n",
    "            self.range = self.upper - self.lower\n",
    "\n",
    "        def fit_transform( self, X ):\n",
    "\n",
    "            i = np.argsort( X, axis = 0 )\n",
    "            j = np.argsort( i, axis = 0 )\n",
    "\n",
    "            assert ( j.min() == 0 ).all()\n",
    "            assert ( j.max() == len( j ) - 1 ).all()\n",
    "\n",
    "            j_range = len( j ) - 1\n",
    "            self.divider = j_range / self.range\n",
    "\n",
    "            transformed = j / self.divider\n",
    "            transformed = transformed - self.upper\n",
    "            transformed = scipy.special.erfinv( transformed )\n",
    "            ############\n",
    "            # transformed = transformed - np.mean(transformed)\n",
    "\n",
    "            return transformed\n",
    "\n",
    "    def transform_freq_feature(df1,df2,df3_base,feat):\n",
    "        val1=df1[feat].values\n",
    "        val2=df3_base[feat].values\n",
    "\n",
    "        defa1=defaultdict(lambda:0)\n",
    "\n",
    "        for val in val1:\n",
    "            defa1[str(val)]+=1.\n",
    "        for val in val2:\n",
    "            defa1[str(val)]+=1.  \n",
    "\n",
    "        df1[feat +\"_freq\"]= df1[feat].apply(lambda x :defa1[str(x)] ) \n",
    "        df2[feat+\"_freq\"]= df2[feat].apply(lambda x :defa1[str(x)] )  \n",
    "\n",
    "    def load_data():\n",
    "        train_df = train[feature_cols].copy()\n",
    "        test_df = test[feature_cols].copy()\n",
    "        real_test_df = test[feature_cols].copy()\n",
    "\n",
    "        unique_samples = []\n",
    "        unique_count = np.zeros_like(test_df)\n",
    "        for feature in tqdm(range(test_df.shape[1])):\n",
    "            _, index_, count_ = np.unique(test_df.values[:, feature], return_counts=True, return_index=True)\n",
    "            unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "        # Samples which have unique values are real the others are fake\n",
    "        real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "        synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "\n",
    "        real_test_df=real_test_df.iloc[real_samples_indexes]\n",
    "        print(real_test_df.shape[0])\n",
    "        print(len(synthetic_samples_indexes))\n",
    "\n",
    "        columns=train_df.columns.values\n",
    "        for col in tqdm(columns):\n",
    "            transform_freq_feature(train_df,test_df,real_test_df,col)\n",
    "        '''\n",
    "        train_df = pd.concat([train_df,\n",
    "                              pd.read_pickle('features/unique_sum_per_row_train.pkl')], axis=1)\n",
    "        test_df = pd.concat([test_df,\n",
    "                              pd.read_pickle('features/unique_sum_per_row_test.pkl')], axis=1)\n",
    "\n",
    "        for col in tqdm(columns[[6,110, 26, 146, 139, 21, 76, 174, 133, 99, 198, 109, 80, 13, 190, 148, 0, 44, 164]]):\n",
    "            transform_gmm_feature(train_df,test_df,real_test_df,col)\n",
    "        ''' \n",
    "        print(train_df.isnull().sum().sum(), test_df.isnull().sum().sum(),)\n",
    "        return train_df, test_df, real_samples_indexes\n",
    "    \n",
    "    train_df, test_df, te_real_samples_indexes = load_data()\n",
    "    \n",
    "    '''\n",
    "    for f in tqdm(feature_cols[:200]): # transform into probability\n",
    "        train_df[f] = 1/(1+np.exp(-train_df[f]))\n",
    "        test_df[f] = 1/(1+np.exp(-test_df[f]))\n",
    "    '''   \n",
    "    \n",
    "    '''\n",
    "    for f in tqdm(feature_cols): # normalzie\n",
    "        vals = train_df[f].append(test_df.loc[te_real_samples_indexes,f]).values\n",
    "        m, s = vals.mean(), vals.std()\n",
    "        train_df[f] = (train_df[f]-m)/s\n",
    "        test_df[f] = (test_df[f]-m)/s\n",
    "    '''\n",
    "    for f in tqdm(feature_cols): # normalzie\n",
    "        vals = GaussRankScaler().fit_transform(train_df[f].append(test_df.loc[te_real_samples_indexes,f]).values.reshape((-1,1)))\n",
    "        vals = vals[:,0]\n",
    "        train_df[f] = vals[:train_df.shape[0]]\n",
    "        test_df.loc[te_real_samples_indexes,f] = vals[train_df.shape[0]:]\n",
    "        m, s = vals.mean(), vals.std()\n",
    "        train_df[f] = (train_df[f]-m)/s\n",
    "        test_df[f] = (test_df[f]-m)/s\n",
    "        \n",
    "    print(train_df.isnull().sum().sum(), test_df.isnull().sum().sum(),)\n",
    "    train_df.to_pickle('data/nn_data_preprocessed_train_v3.pkl')\n",
    "    test_df.to_pickle('data/nn_data_preprocessed_test_v3.pkl')\n",
    "else:\n",
    "    train_df = pd.read_pickle('data/nn_data_preprocessed_train.pkl')\n",
    "    test_df = pd.read_pickle('data/nn_data_preprocessed_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 4135914352819612748\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10652409037\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4831855576174646784\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "from keras.layers import Input, SpatialDropout1D,Dropout, GlobalAveragePooling1D, GlobalMaxPooling1D, \\\n",
    "                            CuDNNGRU, GRU, Bidirectional, CuDNNLSTM, Dense, Embedding, concatenate, Embedding, \\\n",
    "                            Flatten, Activation, BatchNormalization, regularizers, Conv1D, Conv2D, MaxPooling2D, Reshape, PReLU, \\\n",
    "                            GaussianNoise, Multiply, Add\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "from keras.initializers import Orthogonal\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback, Callback, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "import gc; gc.enable()\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "from scipy.stats import boxcox\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "#from tqdm import tqdm\n",
    "\n",
    "# check gpu\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 2)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200, 32)           96        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200, 16)           528       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3201      \n",
      "=================================================================\n",
      "Total params: 3,825\n",
      "Trainable params: 3,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "from keras.layers import Dense, Concatenate, Input, Lambda\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, activations\n",
    "from keras.metrics import *\n",
    "\n",
    "gamma = 2.0\n",
    "alpha=.25\n",
    "epsilon = K.epsilon()\n",
    "\n",
    "def focal_loss(y_true, y_pred):\n",
    "    pt_1 = y_pred * y_true\n",
    "    pt_1 = K.clip(pt_1, epsilon, 1-epsilon)\n",
    "    CE_1 = -K.log(pt_1)\n",
    "    FL_1 = alpha* K.pow(1-pt_1, gamma) * CE_1\n",
    "    \n",
    "    pt_0 = (1-y_pred) * (1-y_true)\n",
    "    pt_0 = K.clip(pt_0, epsilon, 1-epsilon)\n",
    "    CE_0 = -K.log(pt_0)\n",
    "    FL_0 = (1-alpha)* K.pow(1-pt_0, gamma) * CE_0\n",
    "    \n",
    "    loss = K.sum(FL_1, axis=1) + K.sum(FL_0, axis=1)\n",
    "    return loss\n",
    "\n",
    "def build_model():\n",
    "    # share components\n",
    "    inputs = Input(shape=(train_df.shape[1]//2,2))\n",
    "    main = inputs\n",
    "    \n",
    "    main = Dense(32, activation='relu')(main)\n",
    "    main = Dense(16, activation='relu')(main)\n",
    "    #main = BatchNormalization()(main)\n",
    "    main = Flatten()(main)\n",
    "    \n",
    "    out = Dense(1, activation = 'sigmoid')(main) # 1 class to be classified\n",
    "\n",
    "    model = Model(inputs, out)\n",
    "    model.regularizers = [regularizers.l2(0.0001)]\n",
    "    \n",
    "    # use over weights\n",
    "    model.compile(optimizer = Adam(lr=0.001, clipnorm=1.), loss=focal_loss, metrics=[\"binary_crossentropy\"])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "from datetime import datetime\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings; warnings.filterwarnings('ignore') \n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "class auc_score_monitor(Callback):\n",
    "    def __init__(self, val_data, val_target, checkpoint_file, min_lr =1e-5, reduce_lr_patience=2, early_stop_patience=4, factor=0.1):\n",
    "        self.val_data = val_data\n",
    "        self.val_target = val_target\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.reduce_lr_patience = reduce_lr_patience\n",
    "        self.early_stop_patience = early_stop_patience\n",
    "        self.best_val_score = 0\n",
    "        self.epoch_num = 0\n",
    "        self.factor = factor\n",
    "        self.unimproved_lr_counter = 0\n",
    "        self.unimproved_stop_counter = 0\n",
    "        self.min_lr = min_lr\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_scores = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_pred = self.model.predict(self.val_data).reshape((-1,))\n",
    "        val_score = roc_auc_score(self.val_target, val_pred)\n",
    "        # clip pred\n",
    "        self.val_scores.append(val_score)\n",
    "        \n",
    "        #print(self.val_target, '\\n', val_pred)\n",
    "        print('Epoch {} val_score: {:.5f}'.format(self.epoch_num, val_score))\n",
    "        self.epoch_num += 1\n",
    "        \n",
    "        if val_score > self.best_val_score:\n",
    "            print ('Val Score improve from {:5f} to {:5f}'.format(self.best_val_score, val_score))\n",
    "            self.best_val_score = val_score\n",
    "            self.unimproved_lr_counter = 0\n",
    "            self.unimproved_stop_counter = 0\n",
    "            if self.checkpoint_file is not None:\n",
    "                self.model.save_weights(self.checkpoint_file)\n",
    "        else:\n",
    "            if val_score-self.best_val_score > 1e-4:\n",
    "                self.unimproved_lr_counter += 1\n",
    "                self.unimproved_stop_counter += 1\n",
    "            \n",
    "        if self.reduce_lr_patience is not None and self.unimproved_lr_counter > self.reduce_lr_patience:\n",
    "            current_lr = K.eval(self.model.optimizer.lr)\n",
    "            if current_lr > self.min_lr:\n",
    "                print('Reduce LR from {:.6f} to {:.6f}'.format(current_lr, current_lr*self.factor))\n",
    "                K.set_value(self.model.optimizer.lr, current_lr*self.factor)\n",
    "                self.model.load_weights(self.checkpoint_file)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            self.unimproved_lr_counter = 0\n",
    "            \n",
    "        if self.early_stop_patience is not None and self.unimproved_stop_counter > self.early_stop_patience:\n",
    "            print('Early Stop Criteria Meet')\n",
    "            self.model.stop_training = True\n",
    "                \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "train_epochs = 50\n",
    "batch_size=32 # 32 or 64 is good (too huge for my PC), 128 is worse in the past experiments\n",
    "cpu_count=4  \n",
    "n_classses = 1\n",
    "fold_num = 4\n",
    "model_prefix = 'nn-stf-v9' #'rnn-with-marcus-features-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 200, 2) (150000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 2)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200, 32)           96        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200, 16)           528       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3201      \n",
      "=================================================================\n",
      "Total params: 3,825\n",
      "Trainable params: 3,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd70842ce0246ddab0be1236a9a3db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=50, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb58e302594540e4bc213f653c318508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.26809, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 0 val_score: 0.90828\n",
      "Val Score improve from 0.000000 to 0.908276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14a353d87254c80b3226c68d6db6c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.26809 to 0.25778, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 1 val_score: 0.91176\n",
      "Val Score improve from 0.908276 to 0.911762\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af4803d6e3d4803bcd75de5390f94e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.25778 to 0.24453, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 2 val_score: 0.91262\n",
      "Val Score improve from 0.911762 to 0.912621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8684abd207da479db7b415f3105721ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy did not improve from 0.24453\n",
      "Epoch 3 val_score: 0.91181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc4d251575949b882f8768a09bad9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.24453 to 0.24406, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 4 val_score: 0.91581\n",
      "Val Score improve from 0.912621 to 0.915806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36147dee60c045968030067b848822d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.24406 to 0.24305, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 5 val_score: 0.91682\n",
      "Val Score improve from 0.915806 to 0.916822\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddeab1da9d4f483a995d21018f157806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.24305\n",
      "Epoch 6 val_score: 0.91729\n",
      "Val Score improve from 0.916822 to 0.917288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b637809fb414596a513a555721680ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.24305 to 0.24219, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 7 val_score: 0.91743\n",
      "Val Score improve from 0.917288 to 0.917432\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d0464873914e408db88b5fbb9cb627",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.24219\n",
      "Epoch 8 val_score: 0.91779\n",
      "Val Score improve from 0.917432 to 0.917787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ccd2d201a045108aa88416f9f0a220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.24219\n",
      "Epoch 9 val_score: 0.91796\n",
      "Val Score improve from 0.917787 to 0.917964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6821f10926f54822a2d6efea90490ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.24219\n",
      "Epoch 10 val_score: 0.91800\n",
      "Val Score improve from 0.917964 to 0.917997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b306598de443ddb0a1bd5055299e03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_binary_crossentropy improved from 0.24219 to 0.24130, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 11 val_score: 0.91802\n",
      "Val Score improve from 0.917997 to 0.918019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3359d3c51fc4b2fae6ccdc7a96197d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.24130\n",
      "Epoch 12 val_score: 0.91798\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e726a137a02b4e1bbf2ed9a709f593bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_binary_crossentropy did not improve from 0.24130\n",
      "Epoch 13 val_score: 0.91806\n",
      "Val Score improve from 0.918019 to 0.918060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043aedb4a3d14586b7c923dde59cf102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_binary_crossentropy improved from 0.24130 to 0.24031, saving model to model_weights/nn-stf-v9_fold_1.hdf5\n",
      "Epoch 14 val_score: 0.91808\n",
      "Val Score improve from 0.918060 to 0.918080\n",
      "\n",
      "(150000, 200, 2) (150000,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 2)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200, 32)           96        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200, 16)           528       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3201      \n",
      "=================================================================\n",
      "Total params: 3,825\n",
      "Trainable params: 3,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddae3b2e3e2e4507b9e3712b8af390f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=50, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781a5591f3f345c982a253544e71992f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 0', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.23789, saving model to model_weights/nn-stf-v9_fold_2.hdf5\n",
      "Epoch 0 val_score: 0.91032\n",
      "Val Score improve from 0.000000 to 0.910325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3221ad30a39a4fd593e87295ded8e218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 1', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_binary_crossentropy did not improve from 0.23789\n",
      "Epoch 1 val_score: 0.91543\n",
      "Val Score improve from 0.910325 to 0.915430\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a13475671834142b3c51ee361c241c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 2', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: val_binary_crossentropy did not improve from 0.23789\n",
      "Epoch 2 val_score: 0.91513\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360af63502254b8294a254d747076ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 3', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.23789 to 0.23707, saving model to model_weights/nn-stf-v9_fold_2.hdf5\n",
      "Epoch 3 val_score: 0.91738\n",
      "Val Score improve from 0.915430 to 0.917382\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c572e1b1a740898fa277cc340a04c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 4', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 4 val_score: 0.91948\n",
      "Val Score improve from 0.917382 to 0.919483\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360ef9d4dc664015984306f65ed17583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 5', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 5 val_score: 0.92021\n",
      "Val Score improve from 0.919483 to 0.920207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8272016833a040269e31b33194167a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 6', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 6 val_score: 0.92053\n",
      "Val Score improve from 0.920207 to 0.920529\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22851c37d7340d6964c91fbfdfdeefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 7', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 7 val_score: 0.92072\n",
      "Val Score improve from 0.920529 to 0.920717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3bd0f52e654ba48e7e9c998e6ac0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 8', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 8 val_score: 0.92080\n",
      "Val Score improve from 0.920717 to 0.920803\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c7808d660e4608af862c9f688b142d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 9', max=150000, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 9 val_score: 0.92077\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7129f72a45477a8c9ccccee6fdfef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 10', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 10 val_score: 0.92081\n",
      "Val Score improve from 0.920803 to 0.920807\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0a2ea501160485bb59ea85aa81cf936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 11', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00012: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 11 val_score: 0.92085\n",
      "Val Score improve from 0.920807 to 0.920852\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0cb3c2618654eff97075a4e259f7e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 12', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 12 val_score: 0.92085\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f9f7b9dbcc4cca8dc0e0779f7328ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 13', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00014: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 13 val_score: 0.92090\n",
      "Val Score improve from 0.920852 to 0.920896\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de839de75bc465abdb24c5896a9d655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 14', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00015: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 14 val_score: 0.92089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8643c160045c4aefb366df6423cff88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 15', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 15 val_score: 0.92093\n",
      "Val Score improve from 0.920896 to 0.920926\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2390acfc232e40c1a4c33699c8fc7cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 16', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00017: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 16 val_score: 0.92095\n",
      "Val Score improve from 0.920926 to 0.920949\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80bda54ce54c4cc99518eac58ef14a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 17', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00018: val_binary_crossentropy did not improve from 0.23707\n",
      "Epoch 17 val_score: 0.92096\n",
      "Val Score improve from 0.920949 to 0.920956\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "147ffdf6f3884644b2c1c0e7d2ad8694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch 18', max=150000, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a36d0c3b512b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                         callbacks = [early_stop, lr_schd, check_point,\n\u001b[1;32m---> 38\u001b[1;33m                                      wmlog_loss_monitor, TQDMNotebookCallback(leave_inner=True, leave_outer=True)])\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#from clr_callback import CyclicLR\n",
    "\n",
    "def special_reshape(vals):\n",
    "    return np.vstack([v.reshape((2,-1)).T.reshape((1, -1, 2)) for v in vals])\n",
    "\n",
    "fold = 0  \n",
    "retrain_fold = None\n",
    "\n",
    "for tr_ix, val_ix in KFold(fold_num, shuffle=True, random_state=seed).split(target, target):    \n",
    "    fold += 1\n",
    "\n",
    "    if retrain_fold is not None and fold not in retrain_fold:\n",
    "        continue\n",
    "        \n",
    "    #if fold < 3: continue\n",
    "        \n",
    "    tr = special_reshape(train_df.values[tr_ix,:])\n",
    "    val = special_reshape(train_df.values[val_ix,:])\n",
    "    tr_y = target[tr_ix]\n",
    "    val_y = target[val_ix]\n",
    "    print(tr.shape, tr_y.shape)\n",
    "\n",
    "    model = build_model()\n",
    "    file_path = \"model_weights/{}_fold_{}.hdf5\".format(model_prefix, fold)\n",
    "\n",
    "    early_stop = EarlyStopping(patience=4)\n",
    "    #lr_schd = LearningRateScheduler(lambda epoch: 0.001*(0.2**(epoch//5)), verbose=1)\n",
    "    lr_schd = ReduceLROnPlateau(factor=0.1, patience=2, min_lr=1e-5, verbose=1)\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_binary_crossentropy\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "    wmlog_loss_monitor = auc_score_monitor(val, target[val_ix], \n",
    "                                                checkpoint_file=None, reduce_lr_patience=None, early_stop_patience=None, \n",
    "                                                factor=None) # calculate weighted m log loss per epoch\n",
    "    \n",
    "    history = model.fit(x=tr, y=tr_y,\n",
    "                        validation_data=(val, val_y),\n",
    "                        epochs=train_epochs, verbose = 0, batch_size=batch_size,\n",
    "                        callbacks = [early_stop, lr_schd, check_point,\n",
    "                                     wmlog_loss_monitor, TQDMNotebookCallback(leave_inner=True, leave_outer=True)])\n",
    "    \n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "# input 400-1, dense 16: 1st fold cv, 50 epoch: 0.891156\n",
    "# (v1) input 200-2, dense 16: cv: CV Mean = 0.91717, Std = 0.00577, all: 0.9172708052064378, lb: 0.919\n",
    "# (v2) input 200-2, dense 32: cv: CV Mean = 0.92025, Std = 0.00274, all: 0.920259859604747, lb: 0.920\n",
    "# (v3) input 200-2, dense 64: cv: CV Mean = 0.92017, Std = 0.00308, all: 0.9201596899376223, lb: \n",
    "# (v4) input 200-2, dense 32-dense 16: cv: CV Mean = 0.92234, Std = 0.00247, 0.9223124284750207, lb: \n",
    "# (v5) input 200-2, dense 32-dense 16-dense 8: cv: CV Mean = 0.92209, Std = 0.00277, 0.9220835129740627, lb:\n",
    "# (v6) input 200-2, dense 32-dense 16-flat-bn-dense 32: cv: bad, cut off, lb:\n",
    "# (v7) input 200-2, dense 32-dense 16 (4 fold): cv: CV Mean = 0.92212, Std = 0.00154, 0.9220763307651896, lb: 0.922\n",
    "# (v8) input 200-2, dense 32-dense 16 (4 fold) + num to prob: cv: \n",
    "#          cv: 0.80 first fold, bad..., lb:\n",
    "# input 200-2, dense 32-dense 16 (4 fold) + rankgauss: # not better (1st fold 0.9185)\n",
    "# input 200-2, dense 32-dense 16 (4 fold) + class weight {0: 0.55, 1: 5}: # not better (1st fold 0.917-8)\n",
    "# input 200-2, dense 32-dense 16 (4 fold) + focal loss: # not better (1st fold 0.918)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_oof = np.zeros((train.shape[0],))\n",
    "test_oof = np.zeros((test.shape[0],))\n",
    "\n",
    "train_aucs = []\n",
    "fold=0\n",
    "for tr_ix, val_ix in KFold(fold_num, shuffle=True, random_state=seed).split(target, target):    \n",
    "    fold += 1\n",
    "    val = special_reshape(train_df.values[val_ix,:])\n",
    "    val_y = target[val_ix]\n",
    "    \n",
    "    model = build_model()\n",
    "    file_path = \"model_weights/{}_fold_{}.hdf5\".format(model_prefix, fold)\n",
    "\n",
    "    # Predict val + test oofs\n",
    "    model.load_weights(file_path) # load weight with best validation score\n",
    "    \n",
    "    pred = model.predict(val, batch_size=batch_size).reshape((len(val_ix),))\n",
    "    train_oof[val_ix] = pred\n",
    "    val_auc = roc_auc_score(target[val_ix], pred)\n",
    "    train_aucs.append(val_auc)\n",
    "    print('val acc = {:.5f}'.format(val_auc))\n",
    "\n",
    "    test_oof += model.predict(special_reshape(test_df.values), batch_size=batch_size).reshape((test.shape[0],))/fold_num\n",
    "    \n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CV Mean = {:.5f}, Std = {:.5f}'.format(np.mean(train_aucs), np.std(train_aucs)))\n",
    "full_auc = roc_auc_score(target, train_oof)\n",
    "print(full_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(train_oof, \"oof+submission/{}_fold_{}_seed_{}_oof_train\".format(model_prefix, fold_num, seed))\n",
    "pd.to_pickle(test_oof, \"oof+submission/{}_fold_{}_seed_{}_oof_test\".format(model_prefix, fold_num, seed))\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "sub[\"target\"] = test_oof\n",
    "sub.to_csv('oof+submission/' + model_prefix + '_' + str(full_auc).replace('.', '_') + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
