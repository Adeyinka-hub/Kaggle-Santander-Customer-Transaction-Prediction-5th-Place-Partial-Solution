{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm; tqdm.pandas()\n",
    "pd.options.display.max_columns = 202\n",
    "pd.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_pickle('data/train_original.pkl')\n",
    "test = pd.read_pickle('data/test_original.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_cols = [col for col in train.columns if train[col].dtype != np.float64]\n",
    "feature_cols = [col for col in train.columns if col not in special_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_vals = pd.Series(np.concatenate(train[feature_cols].values))\n",
    "tst_vals = pd.Series(np.concatenate(test[feature_cols].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02072085, 0.01857135)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_vals.nunique()/len(trn_vals), tst_vals.nunique()/len(tst_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99359275, 0.9970897)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_vals.isin(tst_vals).sum()/len(trn_vals), tst_vals.isin(trn_vals).sum()/len(tst_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del trn_vals, tst_vals; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Countvec to transform features into per value counts vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "all_values = pd.concat([train[feature_cols], test[feature_cols]], axis=0).reset_index(drop=True).values\n",
    "all_values = pd.Series(np.concatenate(all_values))\n",
    "all_values_vc = all_values.value_counts()\n",
    "all_values_vc = all_values_vc[all_values_vc>min_count]\n",
    "all_values = all_values.map(all_values_vc).fillna(-999)\n",
    "all_values = all_values.values.reshape((-1,len(feature_cols)))\n",
    "train_df = pd.DataFrame(data=all_values[:train.shape[0]], columns=feature_cols)\n",
    "test_df = pd.DataFrame(data=all_values[train.shape[0]:], columns=feature_cols)\n",
    "train_df.to_pickle('count vec data/train_cv.pkl')\n",
    "test_df.to_pickle('count vec data/test_cv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2592.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 400000/400000 [00:46<00:00, 8639.31it/s]\n"
     ]
    }
   ],
   "source": [
    "def to_texts(row):\n",
    "    return \" \".join([str(r).replace(\"-\",\"_\") for r in row])\n",
    "\n",
    "all_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
    "all_texts = all_df.progress_apply(to_texts, axis=1)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(dtype=np.float32)\n",
    "all_texts_sparse = cv.fit_transform(all_texts)\n",
    "pd.to_pickle(all_texts_sparse[:train.shape[0]],'count vec data/train_cv_sparse.pkl')\n",
    "pd.to_pickle(all_texts_sparse[train.shape[0]:],'count vec data/test_cv_sparse.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a 10-fold LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('count vec data/train_cv.pkl')\n",
    "test_df = pd.read_pickle('count vec data/test_cv.pkl')\n",
    "#train_df = pd.read_pickle('count vec data/train_cv_sparse.pkl')\n",
    "#test_df = pd.read_pickle('count vec data/test_cv_sparse.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 started at Thu Mar 14 19:59:33 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.324797\tvalid_1's binary_logloss: 0.325842\n",
      "[200]\ttraining's binary_logloss: 0.323642\tvalid_1's binary_logloss: 0.325697\n",
      "[300]\ttraining's binary_logloss: 0.322568\tvalid_1's binary_logloss: 0.325552\n",
      "[400]\ttraining's binary_logloss: 0.321577\tvalid_1's binary_logloss: 0.325544\n",
      "[500]\ttraining's binary_logloss: 0.320579\tvalid_1's binary_logloss: 0.32553\n",
      "Early stopping, best iteration is:\n",
      "[326]\ttraining's binary_logloss: 0.322306\tvalid_1's binary_logloss: 0.32551\n",
      "0.5295218366507743\n",
      "Fold 1 started at Thu Mar 14 20:00:49 2019\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-76d0df396c7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m     model = lgb.train(params,train_data, num_boost_round=3200,\n\u001b[0;32m     45\u001b[0m                     \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                     early_stopping_rounds = 200)\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mfold_importance_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\khyeh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1758\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1760\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1761\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1762\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "version = 'kh_lgb_10fold_vc_ver1'\n",
    "\n",
    "params = {'num_leaves': 8,\n",
    "         'min_data_in_leaf': 42,\n",
    "         'objective': 'binary',\n",
    "         'max_depth': 16,\n",
    "         'learning_rate': 0.03,\n",
    "         'boosting': 'gbdt',\n",
    "         'bagging_freq': 5,\n",
    "         'bagging_fraction': 0.8,\n",
    "         'feature_fraction': 0.8201,\n",
    "         'bagging_seed': 11,\n",
    "         'reg_alpha': 1.7289,\n",
    "         'reg_lambda': 4.984,\n",
    "         'random_state': 42,\n",
    "         'metric': 'binary_logloss',\n",
    "         'verbosity': -1,\n",
    "         'subsample': 0.81,\n",
    "         'min_gain_to_split': 0.01,\n",
    "         'min_child_weight': 19.428,\n",
    "         'num_threads': 2}\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "prediction = np.zeros(len(test))\n",
    "\n",
    "n_fold = 10\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_n, (train_index, valid_index) in enumerate(folds.split(train.target.values,train.target.values)):\n",
    "    \n",
    "    print('Fold', fold_n, 'started at', time.ctime())\n",
    "    X_train, X_valid = train_df[feature_cols].values[train_index], train_df[feature_cols].values[valid_index]\n",
    "    y_train, y_valid = train.target.values[train_index], train.target.values[valid_index]\n",
    "    \n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "        \n",
    "    model = lgb.train(params,train_data, num_boost_round=3200,\n",
    "                    valid_sets = [train_data, valid_data], verbose_eval=100,\n",
    "                    early_stopping_rounds = 200)\n",
    "     \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = feature_cols\n",
    "    fold_importance_df[\"importance\"] = model.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_n + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)    \n",
    "       \n",
    "    oof[valid_index] = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    prediction += model.predict(test_df[feature_cols].values, num_iteration=model.best_iteration)/n_fold\n",
    "    gc.collect()\n",
    "    print(roc_auc_score(y_valid, oof[valid_index]))\n",
    "    \n",
    "full_auc = roc_auc_score(train.target.values, oof)\n",
    "print(full_auc)\n",
    "# baseline: raw features 10 fold: 0.8984\n",
    "# kh_lgb_10fold_vc_ver1: 0.7896"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_pickle(oof, 'oof+submission/'+version+'_oof_train')\n",
    "pd.to_pickle(prediction, 'oof+submission/'+version+'_oof_test')    \n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "sub[\"target\"] = prediction\n",
    "sub.to_csv('oof+submission/' + version + '_' + str(full_auc).replace('.', '_') + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_gain = feature_importance_df[['importance', 'Feature']].groupby('Feature').mean().sort_values('importance', ascending=False)\n",
    "mean_gain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
